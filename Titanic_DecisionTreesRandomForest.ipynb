{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Titanic_DecisionTrees.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI9Z2ngpHBEm"
      },
      "source": [
        "# Predict survival on the Titanic\n",
        "In this Lab, we will apply the tools of machine learning to predict which passengers survived the tragedy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kk1IYr1HBEp"
      },
      "source": [
        "### Dataset\n",
        "The dataset contains 891 observations of 12 variables:\n",
        "* **PassengerId**: Unique ID for each passenger\n",
        "* **Survived**: Survival (0 = No; 1 = Yes)\n",
        "* **Pclass**: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
        "* **Name**: Name\n",
        "* **Sex**: Sex\n",
        "* **Age**: Age\n",
        "* **Sibsp**: Number of Siblings/Spouses Aboard\n",
        "* **Parch**: Number of Parents/Children Aboard\n",
        "* **Ticket**: Ticket Number\n",
        "* **Fare**: Passenger Fare\n",
        "* **Cabin**: Cabin\n",
        "* **Embarked** Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdF4eR36HBEr"
      },
      "source": [
        "# imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ioNxpXHBEx",
        "outputId": "1fb580a3-c7d3-4a47-ba7d-ca1849aca163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "titanic = pd.read_csv('titanic.csv')\n",
        "titanic.drop('Cabin', axis=1, inplace=True) # We Drop this column because it contains a lot of Nan values\n",
        "titanic[\"Age\"].fillna(titanic[\"Age\"].median(),inplace=True)\n",
        "titanic[\"Embarked\"].fillna(\"S\", inplace = True)\n",
        "print ('survival rate =', titanic.Survived.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "survival rate = 0.3838383838383838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJUtgk-AHBE3"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBhQ_8AwHBE4",
        "outputId": "13d76b12-e796-49be-f8dd-b4fbe76f8df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Some of the columns don't have predictive power, so let's specify which ones are included for prediction\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", 'SibSp' ,'Parch', \"Fare\", \"Embarked\"]  \n",
        "# We need now to convert text columns in predictors to numerical ones\n",
        "for col in predictors: # Loop through all columns in predictors\n",
        "    if titanic[col].dtype == 'object':  # check if column's type is object (text)\n",
        "        titanic[col] = pd.Categorical(titanic[col]).codes  # convert text to numerical\n",
        "\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...            Ticket     Fare  Embarked\n",
              "0            1         0       3  ...         A/5 21171   7.2500         2\n",
              "1            2         1       1  ...          PC 17599  71.2833         0\n",
              "2            3         1       3  ...  STON/O2. 3101282   7.9250         2\n",
              "3            4         1       1  ...            113803  53.1000         2\n",
              "4            5         0       3  ...            373450   8.0500         2\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY966SveHBE-",
        "outputId": "f398d7a4-8a39-47cd-82fb-bd6ebf2a0fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Split the data into a training set and a testing set\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(titanic[predictors], titanic['Survived'], test_size=0.3, random_state=1)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=1)\n",
        "clf.fit(X_train, y_train)\n",
        "train_score = clf.score(X_train, y_train)\n",
        "print ('train accuracy =', clf.score(X_train, y_train))\n",
        "print ('test accuracy =', clf.score(X_test, y_test))\n",
        "\n",
        "from sklearn.model_selection import cross_val_score \n",
        "scores = cross_val_score(clf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
        "print('cross validation accuracy =', scores.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy = 0.8073836276083467\n",
            "test accuracy = 0.7723880597014925\n",
            "cross validation accuracy = 0.7890025735986442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "MVrBvFPBHBFD"
      },
      "source": [
        " # Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ElmKVoPHBFF"
      },
      "source": [
        "Let's start with one single tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPpYzJ1FHBFG",
        "outputId": "81aa6d94-82ed-41fe-9658-3d776bf57e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf_dt = DecisionTreeClassifier(random_state=1)\n",
        "clf_dt.fit(X_train, y_train)\n",
        "train_score = clf_dt.score(X_train, y_train)\n",
        "test_score = clf_dt.score(X_test, y_test)\n",
        "print ('train accuracy =', train_score)\n",
        "print ('test accuracy =', test_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy = 0.9887640449438202\n",
            "test accuracy = 0.7574626865671642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivdvMPWJHBFM"
      },
      "source": [
        "Predictions are obtained in the same way of Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoAR48KIHBFN",
        "outputId": "56168561-df45-4baa-de9e-ef13ee5ab11c"
      },
      "source": [
        "y_pred = clf_dt.predict(X_test)\n",
        "print (y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1\n",
            " 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
            " 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
            " 1 0 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0\n",
            " 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1\n",
            " 0 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0\n",
            " 1 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0\n",
            " 0 1 0 1 0 0 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zfAFZB-HBFR",
        "outputId": "5dce400e-2037-409d-f83f-80af7debfd88"
      },
      "source": [
        "y_prob = clf_dt.predict_proba(X_test)\n",
        "print (y_prob)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.25  0.75]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.5   0.5 ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.8   0.2 ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.25  0.75]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.5   0.5 ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.25  0.75]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.5   0.5 ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.8   0.2 ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.5   0.5 ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.25  0.75]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.25  0.75]\n",
            " [ 1.    0.  ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.5   0.5 ]\n",
            " [ 1.    0.  ]\n",
            " [ 0.    1.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95rnNhrRHBFW"
      },
      "source": [
        "Let's play around with some of the decision tree's parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZJDT8-pHBFX",
        "outputId": "b71ea54f-3868-424c-ba33-7053deaa82e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "clf_dt = DecisionTreeClassifier(random_state=1, max_depth=3)\n",
        "clf_dt.fit(X_train, y_train)\n",
        "print ('train accuracy =', clf_dt.score(X_train, y_train))\n",
        "\n",
        "# Cross validation\n",
        "scores_dt = cross_val_score(clf_dt, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
        "print('cross validation accuracy =',scores_dt.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy = 0.8571428571428571\n",
            "cross validation accuracy = 0.8091959073504487\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zne48L_-HBFm"
      },
      "source": [
        "We Predict the probability of a female, Pclass 1 or 2, above age 2.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdUU1uqYHBFn",
        "outputId": "df50904e-87c5-41ab-8886-7fce9c615f70"
      },
      "source": [
        "passenger1=np.array([1, 0, 3, 0, 0, 0, 0]).reshape(1, -1)\n",
        "print ('proba =', clf_dt.predict_proba(passenger1))\n",
        "print ('class =', clf_dt.predict(passenger1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "proba = [[ 0.04347826  0.95652174]]\n",
            "class = [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGjp90ViHBFy"
      },
      "source": [
        "Let's see which are the most important features using the attribute: **feature\\_importances_**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0pQZ4RlHBFz",
        "outputId": "ef8d3148-fb09-4a9f-f4c3-5e19d1e2a69b"
      },
      "source": [
        "feat_imp = pd.DataFrame(clf_dt.feature_importances_, predictors, columns=['Importance'])\n",
        "feat_imp.sort_values('Importance', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>0.611786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>0.189001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.084796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>0.064193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked</th>\n",
              "      <td>0.050225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Importance\n",
              "Sex         0.611786\n",
              "Pclass      0.189001\n",
              "Age         0.084796\n",
              "SibSp       0.064193\n",
              "Embarked    0.050225\n",
              "Parch       0.000000\n",
              "Fare        0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLDPvsvFHBF4"
      },
      "source": [
        "As expected, **Parch** and **Fare** are the least important ones because they were not used for splitting, while **Sex** is the most important one since it was used first for splitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Vi16nLHBF5"
      },
      "source": [
        "# Random Forest\n",
        "A   [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier from sklearn.ensemble import RandomForestClassifier) is an ensemble of [decision trees](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDu3utFQHBF6",
        "outputId": "63f74c24-f255-4285-aea5-1815230073af"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf_rf = RandomForestClassifier(random_state=1)  # by default, 10 trees are used\n",
        "clf_rf.fit(X_train, y_train)\n",
        "print ('train accuracy =', clf_rf.score(X_train, y_train))\n",
        "\n",
        "# Cross validation\n",
        "scores_rf = cross_validation.cross_val_score(clf_rf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
        "print('cross validation accuracy =',scores_rf.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy = 0.974317817014\n",
            "cross validation accuracy = 0.813763415464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rtEZ7eXHBF-"
      },
      "source": [
        "In the same way, you can print the feature importance of all the trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbrwRmiyHBF_",
        "outputId": "eaff6e02-452d-4939-95e8-dd5028273ebd"
      },
      "source": [
        "feat_imp = pd.DataFrame(clf_rf.feature_importances_, predictors, columns=['Importance'])\n",
        "feat_imp.sort_values('Importance', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.266266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.257963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>0.239376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>0.087316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>0.061535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>0.054428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked</th>\n",
              "      <td>0.033116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Importance\n",
              "Age         0.266266\n",
              "Fare        0.257963\n",
              "Sex         0.239376\n",
              "Pclass      0.087316\n",
              "SibSp       0.061535\n",
              "Parch       0.054428\n",
              "Embarked    0.033116"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtTqK2IkHBGC"
      },
      "source": [
        "Random forest, like decision trees have a lot of parameters to tune. Usually, performance does not change linearly with parameters. Let's take as an example, the accuracy as a function of number of trees (**n_estimators**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NAnHUKJvHBGD",
        "outputId": "c1d92ede-be28-4678-c4a2-b2d15bbe2cf5"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trees = range(50)\n",
        "accuracy = np.zeros(50)\n",
        "for idx in range(len(trees)):\n",
        "    clf_rf=RandomForestClassifier(random_state=1, n_estimators=idx + 1)\n",
        "    clf_rf.fit(X_train,y_train)\n",
        "    accuracy[idx]=clf_rf.score(X_test, y_test)  \n",
        "\n",
        "plt.plot(trees, accuracy)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('Number of Trees')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.text.Text at 0xb17fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFfkjVAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x9870358>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x21HdLEuHBGG"
      },
      "source": [
        "In the following, we try to tune manually the following parameters: **min_samples_leaf, min_samples_split, max_depth, n_estimators** in order to increase cross validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM_9vnSeHBGH",
        "outputId": "cf4af2fa-79cb-439d-b393-831f467264b6"
      },
      "source": [
        "clf_rf = RandomForestClassifier(random_state=1, min_samples_leaf=1, min_samples_split=2, max_depth=3, n_estimators=15)\n",
        "clf_rf.fit(X_train, y_train)\n",
        "print ('train accuracy =', clf_rf.score(X_train, y_train))\n",
        "\n",
        "# Cross validation\n",
        "scores_rf = cross_validation.cross_val_score(clf_rf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
        "print('cross validation accuracy =', scores_rf.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy = 0.841091492777\n",
            "cross validation accuracy = 0.786935502575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU7kua7vHBGM"
      },
      "source": [
        "This might be a difficult job to do manually. In other way is to search automatically the best combination of different ranges for these parameters. This is done using **Grid Search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwq-IxZrHBGN"
      },
      "source": [
        "# Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTK_lkQEHBGO",
        "outputId": "cd271264-72d6-4a57-e432-da1198b1a391"
      },
      "source": [
        "from sklearn.grid_search import GridSearchCV\n",
        "params = {'min_samples_leaf':list(range(1,5)),'min_samples_split':list(range(2,10,2)),\n",
        "          'n_estimators':list(range(10,50,10))}\n",
        "clf_rf2=RandomForestClassifier(random_state=1)\n",
        "clf_gs=GridSearchCV(clf_rf2, params, scoring ='accuracy', cv=5)\n",
        "clf_gs.fit(titanic[predictors], titanic[\"Survived\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise',\n",
              "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
              "            oob_score=False, random_state=1, verbose=0, warm_start=False),\n",
              "       fit_params={}, iid=True, n_jobs=1,\n",
              "       param_grid={'min_samples_split': [2, 4, 6, 8], 'n_estimators': [10, 20, 30, 40], 'min_samples_leaf': [1, 2, 3, 4]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FjwJnitHBGR"
      },
      "source": [
        "Print the best score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTFMpWtHHBGS",
        "outputId": "62b3538a-2cb9-43bd-dc62-db76a57ffd4c"
      },
      "source": [
        "clf_gs.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83277216610549942"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBSrxD6tHBGW"
      },
      "source": [
        "Print the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PzerLLcHBGX",
        "outputId": "26538aea-5d46-487c-e3ca-b4ac7be3919a"
      },
      "source": [
        "clf_gs.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 30}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu14DDWbHBGa"
      },
      "source": [
        "Let's use these best parameters and check whether they achieve really the above cv accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MAymrxjHBGb",
        "outputId": "94b9db43-e290-4b30-a090-4771d3b519ed"
      },
      "source": [
        "clf_rf3 = RandomForestClassifier(random_state=1, min_samples_leaf= 4, min_samples_split= 2, n_estimators= 30) \n",
        "clf_rf3.fit(X_train, y_train)\n",
        "print ('train accuracy =', clf_rf3.score(X_train, y_train))\n",
        "\n",
        "scores_rf3 = cross_validation.cross_val_score(clf_rf3, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
        "print('cross validation accuracy =',scores_rf3.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy = 0.886035313002\n",
            "cross validation accuracy = 0.832820954207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "dquVR0aOHBGe"
      },
      "source": [
        "As we can see, grid search allows us to find the best model parameters to improve our accuracy. Now, we can see the most important features of this last classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZDaxHoPHBGf",
        "outputId": "90effae7-6721-4d1f-da2e-31763849d2da"
      },
      "source": [
        "feat_imp = pd.DataFrame(clf_rf3.feature_importances_, predictors, columns=['Importance'])\n",
        "feat_imp.sort_values('Importance', ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>0.387434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fare</th>\n",
              "      <td>0.204499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.147745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pclass</th>\n",
              "      <td>0.130683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SibSp</th>\n",
              "      <td>0.053662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Parch</th>\n",
              "      <td>0.040667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Embarked</th>\n",
              "      <td>0.035311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Importance\n",
              "Sex         0.387434\n",
              "Fare        0.204499\n",
              "Age         0.147745\n",
              "Pclass      0.130683\n",
              "SibSp       0.053662\n",
              "Parch       0.040667\n",
              "Embarked    0.035311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}